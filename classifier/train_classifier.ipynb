{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:05.956105Z",
     "start_time": "2025-05-01T19:43:04.304554Z"
    }
   },
   "source": [
    "import wandb\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from classifier.file_reader import read_files_from_folder\n",
    "from classifier.dataset import BertPandasDataset, collate_fn, create_bert_datasets, preprocess_dataframe\n",
    "from classifier.model import ContinualMultilabelBERTClassifier, MultilabelBERTClassifier\n",
    "\n",
    "FOLDER_PATH = Path(\"train_classifier.ipynb\").parent.absolute()\n",
    "print(FOLDER_PATH)\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/woi/code/Energy-Optimal-Inferencing/classifier\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:06.060702Z",
     "start_time": "2025-05-01T19:43:05.958609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "DATASET = \"boolq\"\n",
    "MODEL_NAME = \"answerdotai/ModernBERT-base\"\n",
    "MINIBATCH_SIZE = 64\n",
    "N_EPOCHS = 50\n",
    "TEST_VAL_SET_SIZE = 0.15\n",
    "\n",
    "benchmark_config_path = Path(f\"{FOLDER_PATH.parent}/config/messplus/boolq.yaml\")\n",
    "\n",
    "# Read and parse the YAML file\n",
    "with benchmark_config_path.open(\"r\") as f:\n",
    "    classifier_config = yaml.safe_load(f)[\"classifier_model\"]\n",
    "\n",
    "f.close()\n",
    "\n",
    "df = read_files_from_folder(f\"{FOLDER_PATH.parent}/data/inference_outputs/boolq\", file_ext=\".csv\")\n",
    "display(df.head())"
   ],
   "id": "5b9cddcf0cc851b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               input_text benchmark_name  \\\n",
       "doc_id                                                                     \n",
       "0        does ethanol take more energy make that produces          boolq   \n",
       "1                  is house tax and property tax are same          boolq   \n",
       "2       is pain experienced in a missing body part or ...          boolq   \n",
       "3       is harry potter and the escape from gringotts ...          boolq   \n",
       "4       is there a difference between hydroxyzine hcl ...          boolq   \n",
       "\n",
       "        label_small  acc_small  energy_consumption_small  \\\n",
       "doc_id                                                     \n",
       "0               0.0        0.0                    13.306   \n",
       "1               0.0        0.0                    20.845   \n",
       "2               1.0        1.0                    20.205   \n",
       "3               1.0        1.0                    21.512   \n",
       "4               1.0        1.0                    22.972   \n",
       "\n",
       "        inference_time_small  label_medium  acc_medium  \\\n",
       "doc_id                                                   \n",
       "0                   0.157293           0.0         0.0   \n",
       "1                   0.143748           0.0         0.0   \n",
       "2                   0.130104           1.0         1.0   \n",
       "3                   0.103894           1.0         1.0   \n",
       "4                   0.128254           1.0         1.0   \n",
       "\n",
       "        energy_consumption_medium  inference_time_medium  \n",
       "doc_id                                                    \n",
       "0                         160.453               0.564679  \n",
       "1                         166.045               0.557246  \n",
       "2                         132.830               0.499714  \n",
       "3                         159.363               0.513891  \n",
       "4                         130.709               0.508619  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>benchmark_name</th>\n",
       "      <th>label_small</th>\n",
       "      <th>acc_small</th>\n",
       "      <th>energy_consumption_small</th>\n",
       "      <th>inference_time_small</th>\n",
       "      <th>label_medium</th>\n",
       "      <th>acc_medium</th>\n",
       "      <th>energy_consumption_medium</th>\n",
       "      <th>inference_time_medium</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does ethanol take more energy make that produces</td>\n",
       "      <td>boolq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.306</td>\n",
       "      <td>0.157293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.453</td>\n",
       "      <td>0.564679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is house tax and property tax are same</td>\n",
       "      <td>boolq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.845</td>\n",
       "      <td>0.143748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.045</td>\n",
       "      <td>0.557246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is pain experienced in a missing body part or ...</td>\n",
       "      <td>boolq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.205</td>\n",
       "      <td>0.130104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132.830</td>\n",
       "      <td>0.499714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is harry potter and the escape from gringotts ...</td>\n",
       "      <td>boolq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.512</td>\n",
       "      <td>0.103894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.363</td>\n",
       "      <td>0.513891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there a difference between hydroxyzine hcl ...</td>\n",
       "      <td>boolq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.972</td>\n",
       "      <td>0.128254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.709</td>\n",
       "      <td>0.508619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:06.187723Z",
     "start_time": "2025-05-01T19:43:06.185845Z"
    }
   },
   "cell_type": "code",
   "source": "display(len(df[\"input_text\"]))",
   "id": "61c14d00def0269c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:06.463736Z",
     "start_time": "2025-05-01T19:43:06.232185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_col = [\"input_text\"]\n",
    "label_cols = [\"label_small\", \"label_medium\"]\n",
    "\n",
    "dataset = df[text_col + label_cols]\n",
    "dataset = preprocess_dataframe(dataset, label_cols=label_cols)\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset, val_dataset, tokenizer = create_bert_datasets(\n",
    "    dataset,\n",
    "    text_col,\n",
    "    label_cols,\n",
    "    model_name=MODEL_NAME,\n",
    "    max_length=1024,\n",
    "    val_ratio=0.10,\n",
    ")\n",
    "\n",
    "# Create DataLoaders with the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "display(f\"Training dataset size: {len(train_dataset)}\")\n",
    "display(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "8d8d8e017b1a5fb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training dataset size: 2943'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation dataset size: 327'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Full model training\n",
    "Training the full model yields strong results but shows overfitting behavior very quickly.\n",
    "We also exhibit local batch instabilities (observable from loss spikes).\n",
    "I tried to adjust the classifier architecture to account for those instabilities.\n",
    "We might need some form of regularization to treat the losses."
   ],
   "id": "4b88053b473f5c7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:42.880627Z",
     "start_time": "2025-05-01T19:43:06.466274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = MultilabelBERTClassifier(\n",
    "    model_name=MODEL_NAME,  # Replace with your preferred BERT variant\n",
    "    num_labels=len(label_cols),\n",
    "    learning_rate=1e-3,\n",
    "    momentum=0.85,\n",
    "    weight_decay=0.01,\n",
    "    batch_size=16,\n",
    "    max_length=128,\n",
    "    warmup_ratio=0.05,\n",
    "    threshold=0.5,\n",
    "    freeze_bert_layers=True,\n",
    "    config=classifier_config,\n",
    ")\n",
    "\n",
    "with wandb.init(\n",
    "    entity=\"tum-i13\",\n",
    "    project=\"mess-plus-classifier-training-offline\",\n",
    "    name=\"minibatch_size-16-mom-0.9\"\n",
    "):\n",
    "\n",
    "    # Train the model\n",
    "    classifier.fit(train_dataset, val_dataset, epochs=1, early_stopping_patience=2)\n",
    "\n",
    "wandb.finish()\n"
   ],
   "id": "53ab35c56cf81282",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:classifier.model:Using device: cuda\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mherbertw\u001B[0m (\u001B[33mtum-i13\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/woi/code/Energy-Optimal-Inferencing/classifier/wandb/run-20250501_214307-6wpn9hw6</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-i13/mess-plus-classifier-training-offline/runs/6wpn9hw6' target=\"_blank\">minibatch_size-16-mom-0.9</a></strong> to <a href='https://wandb.ai/tum-i13/mess-plus-classifier-training-offline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-i13/mess-plus-classifier-training-offline' target=\"_blank\">https://wandb.ai/tum-i13/mess-plus-classifier-training-offline</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-i13/mess-plus-classifier-training-offline/runs/6wpn9hw6' target=\"_blank\">https://wandb.ai/tum-i13/mess-plus-classifier-training-offline/runs/6wpn9hw6</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:classifier.model:Initializing custom BERTClassifier: answerdotai/ModernBERT-base with 2 labels\n",
      "Epoch 1/5 [Training]: 100%|██████████| 184/184 [00:27<00:00,  6.63it/s, loss=0.5148, batch_loss=0.6345, lr=0.001]\n",
      "Epoch 1/5 [Validation]: 100%|██████████| 21/21 [00:03<00:00,  6.29it/s, val_loss=0.7940, avg_val_loss=0.5499]\n",
      "INFO:classifier.model:Epoch 1/5 - Time: 31.10s\n",
      "INFO:classifier.model:  Train Loss: 0.5425 - Val Loss: 0.5499\n",
      "INFO:classifier.model:  Val Metrics - Accuracy: 0.7645, F1: 0.8666, F1(macro): 0.8649\n",
      "INFO:classifier.model:  Per-label metrics:\n",
      "INFO:classifier.model:    Label 0: F1=0.8216, Prec=0.6972, Rec=1.0000\n",
      "INFO:classifier.model:    Label 1: F1=0.9082, Prec=0.8318, Rec=1.0000\n",
      "INFO:classifier.model:  ✓ Best model saved!\n",
      "Epoch 2/5 [Training]: 100%|██████████| 184/184 [00:26<00:00,  6.86it/s, loss=0.5408, batch_loss=0.8077, lr=0.001]\n",
      "Epoch 2/5 [Validation]: 100%|██████████| 21/21 [00:03<00:00,  7.00it/s, val_loss=0.7884, avg_val_loss=0.5481]\n",
      "INFO:classifier.model:Epoch 2/5 - Time: 29.81s\n",
      "INFO:classifier.model:  Train Loss: 0.5300 - Val Loss: 0.5481\n",
      "INFO:classifier.model:  Val Metrics - Accuracy: 0.7645, F1: 0.8666, F1(macro): 0.8649\n",
      "INFO:classifier.model:  Per-label metrics:\n",
      "INFO:classifier.model:    Label 0: F1=0.8216, Prec=0.6972, Rec=1.0000\n",
      "INFO:classifier.model:    Label 1: F1=0.9082, Prec=0.8318, Rec=1.0000\n",
      "INFO:classifier.model:  ✗ No improvement: 1/2\n",
      "Epoch 3/5 [Training]: 100%|██████████| 184/184 [00:26<00:00,  6.86it/s, loss=0.5445, batch_loss=0.5344, lr=0.001]\n",
      "Epoch 3/5 [Validation]: 100%|██████████| 21/21 [00:02<00:00,  7.06it/s, val_loss=0.7341, avg_val_loss=0.5402]\n",
      "INFO:classifier.model:Epoch 3/5 - Time: 29.80s\n",
      "INFO:classifier.model:  Train Loss: 0.5270 - Val Loss: 0.5402\n",
      "INFO:classifier.model:  Val Metrics - Accuracy: 0.7645, F1: 0.8666, F1(macro): 0.8649\n",
      "INFO:classifier.model:  Per-label metrics:\n",
      "INFO:classifier.model:    Label 0: F1=0.8216, Prec=0.6972, Rec=1.0000\n",
      "INFO:classifier.model:    Label 1: F1=0.9082, Prec=0.8318, Rec=1.0000\n",
      "INFO:classifier.model:  ✗ No improvement: 2/2\n",
      "INFO:classifier.model:Early stopping triggered!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch_loss</td><td>▆▅▄▄▅▄▇▃▄▅▂▄▃█▃▇█▇▆▃▇▇▃▆▁▂▇▅▂▇▂▅▂▇▃▆▃▅▄▅</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>learning_rate</td><td>▁▅▇██▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂</td></tr><tr><td>running_loss</td><td>██▇▆▄▃▄▂▄▃▄▄▃▃▄▂▄▃▅▄▆▂▂▂▂▂▂▂▂▂▁▂▂▄▃▁▃▄▄▃</td></tr><tr><td>time/epoch_seconds</td><td>█▁▁</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr><tr><td>val/accuracy</td><td>▁▁▁</td></tr><tr><td>val/f1_macro</td><td>▁▁▁</td></tr><tr><td>val/f1_micro</td><td>▁▁▁</td></tr><tr><td>val/loss</td><td>█▇▁</td></tr><tr><td>val/precision_micro</td><td>▁▁▁</td></tr><tr><td>val/recall_micro</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>551</td></tr><tr><td>batch_loss</td><td>0.53441</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>learning_rate</td><td>0.00042</td></tr><tr><td>running_loss</td><td>0.54455</td></tr><tr><td>time/epoch_seconds</td><td>29.79943</td></tr><tr><td>train/loss</td><td>0.52695</td></tr><tr><td>val/accuracy</td><td>0.76453</td></tr><tr><td>val/f1_macro</td><td>0.8649</td></tr><tr><td>val/f1_micro</td><td>0.86655</td></tr><tr><td>val/loss</td><td>0.54019</td></tr><tr><td>val/precision_micro</td><td>0.76453</td></tr><tr><td>val/recall_micro</td><td>1</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">minibatch_size-16-mom-0.9</strong> at: <a href='https://wandb.ai/tum-i13/mess-plus-classifier-training-offline/runs/6wpn9hw6' target=\"_blank\">https://wandb.ai/tum-i13/mess-plus-classifier-training-offline/runs/6wpn9hw6</a><br> View project at: <a href='https://wandb.ai/tum-i13/mess-plus-classifier-training-offline' target=\"_blank\">https://wandb.ai/tum-i13/mess-plus-classifier-training-offline</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250501_214307-6wpn9hw6/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:42.905459Z",
     "start_time": "2025-05-01T19:44:42.894452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier.predict(texts=[\n",
    "    \"does ethanol take more energy make that produces\",\n",
    "    \"is the liver part of the excretory system\"\n",
    "])"
   ],
   "id": "67502ebaf78d982f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1],\n",
       "        [1, 1]]),\n",
       " array([[0.7006271, 0.8165475],\n",
       "        [0.7049741, 0.8402771]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Continuous learning approach",
   "id": "96b421bb628db007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:43.025676Z",
     "start_time": "2025-05-01T19:44:42.942983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cont_model = ContinualMultilabelBERTClassifier(\n",
    "#     model_name=MODEL_NAME,  # Replace with your preferred BERT variant\n",
    "#     num_labels=len(label_cols),\n",
    "#     learning_rate=8e-7,\n",
    "#     weight_decay=0.01,\n",
    "#     batch_size=16,\n",
    "#     max_length=128,\n",
    "#     warmup_ratio=0.1,\n",
    "#     threshold=0.5,\n",
    "#     freeze_bert_layers=True,\n",
    "#     memory_size=0\n",
    "# )\n",
    "#\n",
    "#\n",
    "# for idx in range(len(dataset)):\n",
    "#     print(f\"Fetching sample {idx}/{len(dataset)}...\")\n",
    "#     sample = BertPandasDataset(df.loc[idx], text_col, label_cols, tokenizer, 128)\n",
    "#     cont_model.incremental_fit(\n",
    "#         new_train_dataset=sample,\n",
    "#         new_val_dataset=val_dataset,\n",
    "#     )\n",
    "#\n",
    "#     if idx % 50 == 0 and idx != 0:\n",
    "#         display(f\"Done.\")\n",
    "#         break\n"
   ],
   "id": "4704d291d21b380",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
